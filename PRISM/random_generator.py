import os
import sys
sys.path.append(os.getcwd())
sys.path.append("./data")
sys.path.append("./tools")
sys.path.append("./Databases")
sys.path.append("./Databases/data")
sys.path.append("./LanguageModel")

import numpy as np
import random
import numpy as np
import generation
import argparse
from ete3 import NCBITaxa
from Databases.tools import tools_sequence as sequ
from LanguageModel import preprocessing_pca as pca

#from 3DOC.tools import tools_blast as blast #If blasting after sequence generation.
#from 3DOC import output_processing #If running 3DOC pipeline after sequence generation.

def determine_prevalences_annotations():
    '''
    Function determines prevalences of annotations in the annotation vectors generated by the preprocessing_pipeline, saves and outputs them.
    
    :return prevalence_go_terms_in_anno_vecs: total prevalence of go_terms in the single vectors in the dataset used for training of the neural network
    :return go_terms_range: prevalence of single go-terms for all vectors in the dataset used for training of the neural network.
    :return prevalence_total_charge_in_anno_vecs: total prevalence of the total charge in the single vectors in the dataset used for training of the neural network
    :return prevalence_total_aa_distribution_in_anno_vecs: total prevalence of the amino acids (amount = length sequence) in the single vectors in the dataset used for training of the neural network
    :return prevalence_total_aa_types_in_anno_vecs: total prevalence of amino acid types (amount) in the single vectors in the dataset used for training of the neural network
    :return prevalence_rna_motif: total prevalence of RNA-motif bases (amount = length RNA-motif) in the single vectors in the dataset used for training of the neural network
    '''

    annotation_vectors = np.load("/beegfs/work/ws/hd_vu199-preprocessing_arnoldt-0/data/training/annotation_vectors.npy")
    rbp_annotation_vectors = np.load("/beegfs/work/ws/hd_vu199-preprocessing_arnoldt-0/data/finetuning/rbp_annotation_vectors.npy")

    print("Number Entries")
    print(len(annotation_vectors))

    #Determines prevalence of number of GO-Terms, aa_types, aa_distribution, total_charge and the number of ligand binding 

    prevalence_go_terms = []
    counter = 0

    for vector in annotation_vectors:
        for element in range(0, 904):
            if vector[element] == 1.0:
                counter += 1
        prevalence_go_terms.append(counter)
        counter = 0
        
    prevalence_aa_types = []
    counter = 0

    for vector in annotation_vectors:
        for element in range(1019, 1027):
            counter += vector[element]
        prevalence_aa_types.append(counter)
        counter = 0
            
    prevalence_aa_distribution = []
    counter = 0

    for vector in annotation_vectors:
        for element in range(999, 1019):
            counter += vector[element]
        prevalence_aa_distribution.append(counter)
        counter = 0

    prevalence_rna_motif = []
    counter = 0

    for vector in rbp_annotation_vectors:
        for element in range(1076, 1124):
            if vector[element] == 1:
                counter += 1
        prevalence_rna_motif.append(counter)
        counter = 0
        
    prevalence_total_charge = []

    for vector in annotation_vectors:
        prevalence_total_charge.append(vector[998])

    np.save("./Databases/data/prevalence_go_terms.npy", prevalence_go_terms)
    np.save("./Databases/data/prevalence_aa_types.npy", prevalence_aa_types)
    np.save("./Databases/data/prevalence_aa_distribution.npy", prevalence_aa_distribution)
    np.save("./Databases/data/prevalence_rna_motif.npy", prevalence_rna_motif)
    np.save("./Databases/data/prevalence_total_charge.npy", prevalence_total_charge)


    #Determining prevlaences for single GO-Terms in dataset.

    element_list = []

    go_terms_range = []

    for element in range(0, 904):
        go_terms_range.append(0)
        
    for vector in annotation_vectors:
        for element in range(0, 904):
            go_terms_range[element] = go_terms_range[element] + vector[element]

    go_terms_range = np.asarray(go_terms_range)/len(annotation_vectors)

    print("Go_Terms_Range")
    print("Max")
    print(go_terms_range.max())
    print("Min")
    print(go_terms_range.min())
    print("Mean")
    print(go_terms_range.mean())
    print("Quantile (0.1-09)")
    print(np.quantile(go_terms_range, 0.1))
    print(np.quantile(go_terms_range, 0.2))
    print(np.quantile(go_terms_range, 0.3))
    print(np.quantile(go_terms_range, 0.4))
    print(np.quantile(go_terms_range, 0.5))
    print(np.quantile(go_terms_range, 0.6))
    print(np.quantile(go_terms_range, 0.7))
    print(np.quantile(go_terms_range, 0.8))
    print(np.quantile(go_terms_range, 0.9))

    np.save("./Databases/data/go_terms_range.npy", go_terms_range)

    return prevalence_go_terms_in_anno_vecs, go_terms_range, prevalence_total_charge_in_anno_vecs, prevalence_total_aa_distribution_in_anno_vecs, prevalence_total_aa_types_in_anno_vecs, prevalence_rna_motif


def random_rna_motif(prevalence_rna_motif):
    '''
    Function prepares a random RNA-motif.
    
    :param prevalence_rna_motif: total prevalence of RNA-motif bases (amount = length RNA-motif) in the single vectors in the dataset used for training of the neural network
    :rna_motif: one-hot encoded random RNA-motif
    '''
    
    length_rna_motif = random.choice(prevalence_rna_motif)
    rna_motif = ""
    bases = ["A", "C", "G", "U"]

    for base_count in range(0, length_rna_motif):
        base = random.choice(bases)
        rna_motif = rna_motif + base
    
    rna_motif = sequ.translate_rna_motif_in_anno_vec(rna_motif)
        
    return rna_motif


def random_annotations_vector_generation(go_terms_annotation, taxonomy_annotation, total_charge_annotation, aa_distribution_annotation, aa_types_annotation, ligand_binding_annotation, prevalence_go_terms_in_anno_vecs, go_terms_range, prevalence_total_charge_in_anno_vecs, prevalence_total_aa_distribution_in_anno_vecs, prevalence_total_aa_types_in_anno_vecs, prevalence_rna_motif):
    '''
    Function prepares a random annotations_vector under consideration of the prevalence and distribution of annotations in the annotation vectors used in the neural network.
    
    :param go_terms_annotation: True/ False to determine, whether the generated random annotations vector should include random go_terms
    :param taxonomy_annotation: True/ False to determine, whether the generated random annotations vector should include a random taxonomy and all progenitors
    :param total_charge_annotation: True/ False to determine, whether the generated random annotations vector should include a random total_charge
    :param aa_distribution_annotation: True/ False to determine, whether the generated random annotations vector should include a random amino acid distribution
    :param aa_types_annotation: True/ False to determine, whether the generated random annotations vector should include random amino acid types
    :param ligand_binding_annotation: True/ False to determine, whether the generated random annotations vector should include positive Ligand-binding annotation
    :param prevalence_go_terms_in_anno_vecs: total prevalence of go_terms in the single vectors in the dataset used for training of the neural network
    :param go_terms_range: prevalence of single go-terms for all vectors in the dataset used for training of the neural network.
    :param prevalence_total_charge_in_anno_vecs: total prevalence of the total charge in the single vectors in the dataset used for training of the neural network
    :param prevalence_total_aa_distribution_in_anno_vecs: total prevalence of the amino acids (amount = length sequence) in the single vectors in the dataset used for training of the neural network
    :param prevalence_total_aa_types_in_anno_vecs: total prevalence of amino acid types (amount) in the single vectors in the dataset used for training of the neural network
    :param prevalence_rna_motif: total prevalence of RNA-motif bases (amount = length RNA-motif) in the single vectors in the dataset used for training of the neural network
    :return annotations_vector: randomly generated annotations vector, which can be inputted into the neural network.
    '''
    
    annotations_list = []
    annotations_array = np.array([])
    annotations_vector_description = np.load("./Databases/data/annotations_vector_description.npy")

    distribution_code = 'ARNDCQEGHILKMFPSTWYV' #FALSCHER DISTRIBUTION CODE - EVENTUELL EVAL AUCH FALSCH
    aa_distribution = []
    aa_types_description = ["#POSITIVE", "#NEGATIVE", "#POLAR", "#NONPOLAR", "#HYDROXY", "#SULF", "#AROMATIC", "#AMIDE"]
    aa_types = []
    total_charge_list = []    
    #Please note, that semantic similarity, whoch is taken into account in the preprocessing_pipeline is not considered in this pipeline.
    go_terms_numbers_list = []
    for element in range(0, len(go_terms_range)):
        go_terms_numbers_list.append(element)

    if go_terms_annotation == True:
        number_go_terms = random.choice(prevalence_go_terms_in_anno_vecs)
        
        go_term_numbers = []
        go_term_list = []
        go_terms = []
        recurrent_go_term = True
        
        for go_term in range(0, number_go_terms):
            while recurrent_go_term:
                go_term_number = random.choices(go_terms_numbers_list, go_terms_range)
                if go_term_number not in go_term_numbers:
                    go_term_numbers.append(go_term_number)
                    recurrent_go_term = False
            recurrent_go_term = True
            
        for go_term_number in go_term_numbers:
            go_term = str(annotations_vector_description[go_term_number][0])
            go_terms.append(go_term)
            
        for element in annotations_vector_description[0:904]:
            if element in go_terms:
                go_term_list.append(1.0)
            else:
                go_term_list.append(0.0)
      
    if taxonomy_annotation == True:  

        ncbi = NCBITaxa()
        taxonomy_list = []        
        taxonomy = random.choice(annotations_vector_description[904:998])
        taxonomy = taxonomy[4:]
        taxid = ncbi.get_name_translator([taxonomy])
        taxonomy_lineage_list = ncbi.get_lineage(taxid[taxonomy][0])
        taxonomies = ncbi.get_taxid_translator(taxonomy_lineage_list)
        taxonomies = list(taxonomies.values())
        
        taxonomies_list = []
        
        for element in annotations_vector_description[904:998]:
            if element[4:] in taxonomies:
                taxonomies_list.append(1.0)
            else:
                taxonomies_list.append(0.0)

    if total_charge_annotation == True:
        
        total_charge = random.choice(prevalence_total_charge_in_anno_vecs)
        total_charge_list.append(total_charge)
        
    if aa_distribution_annotation == True:    
        total_count = random.choice(prevalence_total_aa_distribution_in_anno_vecs)
        aa_distribution_prevalence = np.random.dirichlet(np.ones(len(distribution_code)),size=1)
        for aa_distributed in range(0, len(aa_distribution_prevalence[0])):
            aa_distribution_count = aa_distribution_prevalence[0][aa_distributed] * total_count
            aa_distribution.append(aa_distribution_count)

    if aa_types_annotation == True:        
        total_count = random.choice(prevalence_total_aa_types_in_anno_vecs)
        aa_types_prevalence = np.random.dirichlet(np.ones(len(aa_types_description)),size=1)
        for aa_type in range(0, len(aa_types_prevalence[0])):
            aa_type_count = aa_types_prevalence[0][aa_type] * total_count
            aa_types.append(aa_type_count)
    
    #It is assumed that all generated annotation vectors do bind a ligand as they all bind a RNA-motif. 
    if ligand_binding_annotation == True:
        ligand_binding = [1.0]


    spacer = [0] * 48
        
    rna_motif = list(random_rna_motif(prevalence_rna_motif))
    
    annotations_vector = go_term_list + taxonomies_list + total_charge_list + aa_distribution + aa_types + ligand_binding + spacer + rna_motif
    
    annotations_vector = np.asarray(annotations_vector)
    
    return annotations_vector
    
    
if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("--number_annotation_vector", help="number of annotation vectors generated and inputted into PRISM", type=int)
    args = parser.parse_args()
    number_annotation_vector  = args.number_annotation_vector

    if not os.path.isdir("LanguageModel/output"):
        os.mkdir("LanguageModel/output")
    
    try:
        prevalence_go_terms_in_anno_vecs = np.load("./Databases/data/prevalence_go_terms.npy")
        go_terms_range = np.load("./Databases/data/go_terms_range.npy")
        prevalence_total_charge_in_anno_vecs = np.load("./Databases/data/prevalence_total_charge.npy")
        prevalence_total_aa_distribution_in_anno_vecs = np.load("./Databases/data/prevalence_aa_types.npy")
        prevalence_total_aa_types_in_anno_vecs = np.load("./Databases/data/prevalence_aa_distribution.npy")
        prevalence_rna_motif = np.load("./Databases/data/prevalence_rna_motif.npy")
    
    except:
        print("The numpy vectors with the prevalences of the annotations in your dataset do not exist. They are generated now, which may take some time. Please note, that generation may need to be adjusted for variable annotations vector lengths.")
        prevalence_go_terms_in_anno_vecs, go_terms_range, prevalence_total_charge_in_anno_vecs, prevalence_total_aa_distribution_in_anno_vecs, prevalence_total_aa_types_in_anno_vecs, prevalence_rna_motif = determine_prevalences_annotations() 
    
    print("Random annotations vector generation starting.")
           
    go_terms_annotation = True
    taxonomy_annotation = True
    total_charge_annotation = True
    aa_distribution_annotation = True
    aa_types_annotation = True
    ligand_binding_annotation = True
    
    annotation_vectors_array = []
	
    for vector in range(0, number_annotation_vector):
    
        annotations_vector = random_annotations_vector_generation(go_terms_annotation, taxonomy_annotation, total_charge_annotation, aa_distribution_annotation, aa_types_annotation, ligand_binding_annotation, prevalence_go_terms_in_anno_vecs, go_terms_range, prevalence_total_charge_in_anno_vecs, prevalence_total_aa_distribution_in_anno_vecs, prevalence_total_aa_types_in_anno_vecs, prevalence_rna_motif)
        
        annotation_vectors_array.append(annotations_vector) 
        
        annotations_vector = annotations_vector.reshape(1,-1)
        
        annotations_vector, _ = pca.preprocessing_pca(annotations_vector, annotations_vector)

        sequence = generation.generation(annotations_vector)    

        fasta_sequence = open("./LanguageModel/output/" + str(vector) + ".fasta","w") 
        fasta_sequence.write(sequence[0])
        fasta_sequence.close()
	
        # If intended, functions can blust against RCSB respectively Swissprot
        #print("Blast against RCSB database.")
        #_, _, _, _, _ = blast.blast_aa_sequence(sequence, "pdb")
        #print("Blast against Swissprot database.")
        #_, _, _, _, _ = blast.blast_aa_sequence(sequence, "swissprot")
	
	# If intended, function can call threedoc_pipline from 3DOC. (Requires running setup.py from tool '3DOC')
        #print("Build PDB with 3DOC and trRosetta.")
        #output_processing.threedoc_pipeline("./LanguageModel/output/", "trRosetta", 3, "best_energy_model")
    
    annotation_vectors_array = np.asarray(annotation_vectors_array)
    
    np.save("./LanguageModel/output/annotation_vectors.npy", annotation_vectors_array)
    
    print("Fasta files of generated sequences are saved in the folder './LanguageModel/output'. Random annotation_vectors are saved in the folder './LanguageModel/output' as well.")
